---
layout: ../layouts/SiteLayout.astro
title: Report your orientation within the hurricane
description: Conducting a depth-first search of the universe, one topic at a time.
---

I'm Adam Hyland, I care a lot about making the invisible parts of systems all around us easier to understand. Not just so we become better informed (which is cool) but so we are equipped to play with, break, and transform those systems (which is way cooler).

---

*Computer Arithmetic:*

My interest in computer arithmetic is in demonstrating and teaching the dramatic impact and importance of this invisible, negotiated, coordinated part of our world. Arithmetic on computers has moved from a central part of programmer training to being supplied by a vast array of libraries and standardized interfaces. Showing how this embedding works and has changed us as users, programmers, and designers is my goal.

- The "Fast" Inverse (Reciprocal) Square Root: In 2009 I wrote a Wikipedia article about a famously terse bit of code to help people understand it. Now I maintain [0x5f37642f.com](https://0x5f37642f.com), which helps people understand how the spread and use of a strange access to the logarithm in floating point arithmetic.
- [Coordinating Arithmetic](http://coordinating-arithmetic.com): A Sloan Foundation funded (Sloan Grant number G-2023-21011) project to document the history of how we standardized computer arithmetic with IEEE 754 through oral history interviews and archival research.
- I am the co-secretary for the upcoming IEEE 754-2029 working group, which determines standards for binary and decimal floating point arithmetic, excluding those covered under P3109, the machine learning floating point standards group.

*AI Image Generation:*

I want to help designers and artists understand the promise and limitations of machine image generation, principally through exploring and experimenting with abberant and adversarial image prompts. Doing so is effective in helping people care about and inspect their functioning, which is increasingly critical as more and more of our visual culture is generated by these systems.

- [Generative AI Glitch Art: Looking for meaning in all the wrong places](https://youtu.be/r-V-qqLJLF8), for VCU's Workshop on the Workshop--the 14th of March, 2023.
- [Grappling with widespread machine image generation](/presentations/GATech-CS3001-generation.pdf): Slides for a talk at Georgia Tech's CS3001 course, July 19 2023.
- Hands Are Hard: Unlearning How We Talk About Machine Learning in the Arts, listed below, is an attempt to introduce artists to machine image generation by focusing on an area where early generators like Stable Diffusion struggle: human hands. Artists must understand how these systems work; one highly effective way to do so is to understand where they don't.

*Interpretability and Robustness of Large Language Models:*

My work with [Ruoxi Shang](https://ruoxishang.com) investigates new challenges with Large Language Models (LLMs) like GPT-4 and Llama as trustworthy interfaces to computing. Making sense of how model output can be understood (interpretability) and how models can be protected from manipulated input (robustness) is crucial for ensuring aligned behavior in high-stakes, high-complexity tasks, more of which are being turned over to LLMs every day.

- [Interpreting Robustness](https://docs.google.com/spreadsheets/d/15-f4mxW3niQ3myJAo3V0unLiFlbG9ru4HYthBh6eWbk/edit?usp=sharing) was a course offered in Spring 2023 in University of Washington's Human Centered Design and Engineering department where students from inside and outside computer science engage with cutting edge research on the topic. Our aim is to expose students to the deep connections between model interpretability and robustness, connections which are understudied in the literature.

*Software:*

I build and maintain the following with/via/because/despite agentic coding:
- **SANDBOX_LORE** ([https://github.com/Protonk/SANDBOX_LORE](https://github.com/Protonk/SANDBOX_LORE)) is a host-bound, local-first “live textbook” for Apple’s Seatbelt sandbox built around reproducible evidence instead of narrative authority. It anchors questions to a specific macOS baseline and answers them by generating artifacts you can inspect and rerun—compiled profiles, decoded structure, mappings, and runtime probes—then promotes the results into a test-pinned model so drift becomes visible. The aim is to make the sandbox legible end-to-end, from policy bytes to observed behavior, without pretending macOS enforcement is a single clean layer.
- **PolicyWitness** ([https://github.com/Protonk/PolicyWitness](https://github.com/Protonk/PolicyWitness)) is a macOS app-bundle laboratory for App Sandbox and entitlements: a CLI drives a set of sandboxed XPC services representing different profiles and runs probes in-process for cleaner, more comparable outcomes. Each run emits structured JSON plus optional supporting evidence (e.g., denial logs/signposts) so “what happened” is recorded without guesswork. A notarized copy of the most recent build is vendored in SANDBOX_LORE.
- **fencerunner** ([https://github.com/Protonk/fencerunner](https://github.com/Protonk/fencerunner)) is a Rust CLI that turns a folder of shell scripts into a strict, schema-validated NDJSON interface. You declare small contracts up front, then each script must produce one well-formed record, making it easy for downstream tools to consume results reliably—even when scripts fail.

---

*Peer Reviewed Publications:*

- Perkins, K., Ghosh, S., Vera, J., Aragon, C., & Hyland, A. (2022). The Persistence of Safety Silence: How Flight Deck Microcultures Influence the Efficacy of Crew Resource Management. _International Journal of Aviation, Aeronautics, and Aerospace_, 9(3). DOI: [https://doi.org/10.15394/ijaaa.2022.1728](https://doi.org/10.15394/ijaaa.2022.1728)
- Keyes, Oscar K. and Hyland, Adam (2023) "[Hands Are Hard: Unlearning How We Talk About Machine Learning in the Arts](https://digitalscholarship.unlv.edu/tradition_innovations/vol1/iss1/4/)," _Tradition Innovations in Arts, Design, and Media Higher Education_, 1(1)
- Hyland, Adam and Ali, Murtaza (2024) "[Tinker or Transfer? A Tale of Two Techniques in Teaching Visualization](https://arxiv.org/abs/2404.10967),"
- Charlotte P. Lee and Adam Hyland. 2025. Floating Points. In Proceedings of the sixth decennial Aarhus conference: Computing X Crisis (AAR '25). Association for Computing Machinery, New York, NY, USA, 305–313. [https://doi.org/10.1145/3744169.3744191](https://doi.org/10.1145/3744169.3744191)

---

*Teaching:*

I teach Information Visualization, a complex and tool-laden topic like so much in Human-Computer Interaction. My approach--which I feel helps students remain curious in a space like this--is to show that struggling with tools (many of which represent thousands upon thousands of person-hours of work) is **not their fault**. Really excellent visualization and in many ways, the kinds of personal growth we sometimes call '_learning_', can only occur if we productively struggle together.

Courses taught:

- HCDE 411 -- Information Visualization for Undergraduates
  - Autumn 2022, Spring 2023 (With Murtaza Ali), Autumn 2023 (With Murtaza Ali), Winter 2024 (With Murtaza Ali)
- HCDE 511 -- Information Visualization for Masters Students
  - Winter 2023 (With Murtaza Ali), Summer 2023 (With Dr. Brock Craft)

---

*Other:*

- [Missing on the net](/topics/missing): A small collection of documents which for whatever reason aren't on the web elsewhere.

---

Find me on [LinkedIn](https://www.linkedin.com/in/adampunk/).
